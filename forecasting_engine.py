import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import timedelta

# --- MACHINE LEARNING & STATS ---
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.multioutput import MultiOutputRegressor
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_extraction.text import CountVectorizer

# --- SAFE IMPORTS FOR ADVANCED MODELS ---
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False

try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except ImportError:
    XGB_AVAILABLE = False

try:
    from lifelines import CoxPHFitter
    LIFELINES_AVAILABLE = True
except ImportError:
    LIFELINES_AVAILABLE = False

try:
    from statsmodels.tsa.api import VAR
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

# ==========================================
# 1. VISUALIZATION ENGINE (Blue/Red Standard)
# ==========================================
def plot_industrial_forecast(history_df, forecast_df, title, y_label):
    """
    Standardized Industrial Plotting:
    - History: Blue Lines
    - Forecast: Red Dashed Lines
    """
    fig = go.Figure()

    # Historical Data (Blue)
    if not history_df.empty:
        fig.add_trace(go.Scatter(
            x=history_df['ds'], y=history_df['y'],
            mode='lines', name='Historical',
            line=dict(color='#1f77b4', width=2) # Blue
        ))

    # Forecast Data (Red)
    if not forecast_df.empty:
        fig.add_trace(go.Scatter(
            x=forecast_df['ds'], y=forecast_df['yhat'],
            mode='lines', name='Forecast',
            line=dict(color='#d62728', width=2, dash='dash') # Red
        ))

    fig.update_layout(
        title=title,
        xaxis_title="Date",
        yaxis_title=y_label,
        template="plotly_white",
        hovermode="x unified"
    )
    return fig

# ==========================================
# 2. MODEL 1: NEXT MONTH TOTAL COST (Prophet)
# ==========================================
def model_total_cost_prophet(df, periods=30):
    if not PROPHET_AVAILABLE: return None, "Prophet not installed"
    
    # Prep Data
    daily = df.groupby('Created_Date')['TotSum (actual)'].sum().reset_index()
    daily.columns = ['ds', 'y']
    
    if len(daily) < 14: return None, "Insufficient data (<14 days)"

    # Model
    m = Prophet(daily_seasonality=False, yearly_seasonality=False)
    m.add_seasonality(name='monthly', period=30.5, fourier_order=5)
    m.fit(daily)
    
    # Forecast
    future = m.make_future_dataframe(periods=periods)
    forecast = m.predict(future)
    
    # Split for viz
    forecast_segment = forecast.tail(periods)
    
    return (daily, forecast_segment), "Success"

# ==========================================
# 3. MODEL 2: COST CENTER SPENDING (VAR)
# ==========================================
def model_cost_center_var(df):
    if not STATSMODELS_AVAILABLE: return None, "Statsmodels not installed"
    
    # Pivot Data: Date x CostCenter
    if 'Cost Center' not in df.columns: return None, "Missing 'Cost Center' column"
    
    pivot_df = df.pivot_table(index='Created_Date', columns='Cost Center', values='TotSum (actual)', aggfunc='sum').fillna(0)
    pivot_df = pivot_df.resample('W').sum() # Weekly aggregation for stability
    
    if len(pivot_df) < 10: return None, "Insufficient weekly data points"

    try:
        model = VAR(pivot_df)
        results = model.fit(maxlags=2)
        lag_order = results.k_ar
        
        # Forecast 4 weeks ahead
        forecast_input = pivot_df.values[-lag_order:]
        fc = results.forecast(y=forecast_input, steps=4)
        
        fc_df = pd.DataFrame(fc, index=pd.date_range(start=pivot_df.index[-1], periods=5, freq='W')[1:], columns=pivot_df.columns)
        return fc_df, "Success"
    except Exception as e:
        return None, str(e)

# ==========================================
# 4. MODEL 3: HIGH-VALUE REPAIR PROB (XGBoost)
# ==========================================
def model_high_value_repair_xgb(df):
    if not XGB_AVAILABLE: return None, "XGBoost not installed"
    
    # Feature Engineering
    df_ml = df.copy()
    threshold = df_ml['TotSum (actual)'].quantile(0.85) # Top 15% are "High Value"
    df_ml['Is_High_Value'] = (df_ml['TotSum (actual)'] > threshold).astype(int)
    
    # Basic Features
    df_ml['Month'] = df_ml['Created_Date'].dt.month
    df_ml['Day'] = df_ml['Created_Date'].dt.dayofweek
    
    # Encode Description length as proxy for complexity
    df_ml['Desc_Len'] = df_ml['Description'].astype(str).str.len()
    
    features = ['Month', 'Day', 'Desc_Len']
    X = df_ml[features].fillna(0)
    y = df_ml['Is_High_Value']
    
    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
    model.fit(X, y)
    
    # Return feature importance
    importance = pd.DataFrame({'Feature': features, 'Importance': model.feature_importances_})
    return importance.sort_values('Importance', ascending=False), f"Threshold > {threshold:.2f}"

# ==========================================
# 5. MODEL 4: MECH VS ELEC SPLIT (Multi-Output Regression)
# ==========================================
def model_mech_elec_split(df):
    # Heuristic labeling if explicit columns don't exist
    df['Type'] = df['Description'].astype(str).str.lower().apply(
        lambda x: 'Electrical' if any(w in x for w in ['sensor', 'motor', 'fuse', 'cable']) else 'Mechanical'
    )
    
    daily_split = df.groupby(['Created_Date', 'Type'])['TotSum (actual)'].sum().unstack(fill_value=0)
    daily_split['Total_Orders'] = df.groupby('Created_Date')['Order'].count()
    
    daily_split = daily_split.resample('W').sum().fillna(0)
    
    if len(daily_split) < 5: return None, "Insufficient Data"
    
    # Predict Mech and Elec cost based on Order Volume
    X = daily_split[['Total_Orders']]
    y = daily_split[['Mechanical', 'Electrical']] if 'Electrical' in daily_split.columns else daily_split
    
    model = MultiOutputRegressor(RandomForestRegressor())
    model.fit(X, y)
    
    return daily_split, model

# ==========================================
# 6. MODEL 5: AVG REPAIR COST (Random Forest)
# ==========================================
def model_avg_cost_rf(df):
    # Features: Text Length, Equipment ID encoded
    df['Desc_Len'] = df['Description'].astype(str).str.len()
    le = LabelEncoder()
    df['Equip_Enc'] = le.fit_transform(df['Equipment description'].astype(str))
    
    X = df[['Desc_Len', 'Equip_Enc']]
    y = df['TotSum (actual)']
    
    rf = RandomForestRegressor(n_estimators=50)
    rf.fit(X, y)
    
    return rf, "Model Trained"

# ==========================================
# 7. MODEL 6: TOP FAILING ASSETS (Survival/CoxPH)
# ==========================================
def model_survival_analysis(df):
    if not LIFELINES_AVAILABLE: return None, "Lifelines not installed"
    
    # Calculate Duration (Time since last failure)
    df_sorted = df.sort_values(['Equipment description', 'Created_Date'])
    df_sorted['Prev_Date'] = df_sorted.groupby('Equipment description')['Created_Date'].shift(1)
    df_sorted['Days_Since'] = (df_sorted['Created_Date'] - df_sorted['Prev_Date']).dt.days
    
    survival_data = df_sorted.dropna(subset=['Days_Since'])
    survival_data['Event'] = 1 # All records here are failures
    
    if len(survival_data) < 10: return None, "Insufficient intervals"
    
    # Use only equipment with >2 failures
    counts = survival_data['Equipment description'].value_counts()
    valid_equip = counts[counts > 2].index
    survival_data = survival_data[survival_data['Equipment description'].isin(valid_equip)]
    
    # Dummy encoding for equipment is too heavy for small data, using simple mean encoding or just TBF
    # For robust CoxPH, we need covariates. Here we just return the TBF stats as Cox requires distinct covariates
    return survival_data.groupby('Equipment description')['Days_Since'].mean().sort_values(), "Mean TBF Calculated"

# ==========================================
# 8. MODEL 7: SPARE PART CLASSIFICATION (Zero-Shot / NLP)
# ==========================================
def model_spare_part_classifier(df):
    # Zero-Shot requires heavy transformers. We use a Keyword-Bag Fallback for speed/stability.
    categories = {
        'Bearings': ['bearing', 'ball', 'roller'],
        'Seals': ['seal', 'gasket', 'ring'],
        'Electrical': ['sensor', 'fuse', 'cable', 'switch', 'motor'],
        'Hydraulic': ['pump', 'valve', 'cylinder', 'hose'],
        'Fasteners': ['bolt', 'nut', 'screw', 'washer']
    }
    
    def classify(text):
        text = str(text).lower()
        for cat, keywords in categories.items():
            if any(k in text for k in keywords):
                return cat
        return 'General/Consumable'

    classified = df['Description'].apply(classify).value_counts()
    return classified

# ==========================================
# 9. MODEL 8: HOTSPOT DETECTION (DBSCAN)
# ==========================================
def model_hotspot_dbscan(df):
    if 'Functional Location' not in df.columns: return None, "No Location Column"
    
    # Encode locations to numerical space
    le = LabelEncoder()
    coords = le.fit_transform(df['Functional Location'].astype(str)).reshape(-1, 1)
    
    # Cluster
    db = DBSCAN(eps=3, min_samples=5).fit(coords)
    df['Cluster'] = db.labels_
    
    hotspots = df[df['Cluster'] != -1]['Functional Location'].value_counts()
    return hotspots

# ==========================================
# 10. MODEL 9: CRITICAL LINE (Markov Chain)
# ==========================================
def model_line_markov(df):
    # Simulate Line Status based on Order Types (Breakdown = Down, PM = Running)
    # 0 = Running, 1 = Down
    df['State'] = np.where(df['Order Type'] == 'Breakdown maintenance', 1, 0)
    df_sorted = df.sort_values('Created_Date')
    
    transitions = np.zeros((2, 2))
    
    states = df_sorted['State'].values
    for (i, j) in zip(states, states[1:]):
        transitions[i][j] += 1
        
    # Normalize
    trans_prob = transitions / transitions.sum(axis=1, keepdims=True)
    return trans_prob

# ==========================================
# MAIN WRAPPER FOR APP
# ==========================================
def deep_six_month_analyzer(df):
    st.markdown("## ðŸ­ Industrial AI Analytics Engine")
    st.markdown("Automatic selection of statistical models based on data topology.")
    
    if 'Created_Date' not in df.columns:
        st.error("Error: 'Created_Date' column is missing.")
        return

    # 1. Total Cost Forecast (Prophet)
    st.subheader("1. Next Month Total Cost (Prophet)")
    data, status = model_total_cost_prophet(df)
    if data:
        hist, fcst = data
        fig = plot_industrial_forecast(hist, fcst, "Total Maintenance Cost Forecast", "Cost (LKR)")
        st.plotly_chart(fig, use_container_width=True)
        next_m_sum = fcst['yhat'].sum()
        st.info(f"Predicted Spend Next 30 Days: **LKR {next_m_sum:,.2f}**")
    else:
        st.warning(f"Skipped: {status}")

    # 2. Mech vs Elec Split
    st.subheader("2. Mechanical vs Electrical Forecasting")
    split_data, _ = model_mech_elec_split(df)
    if split_data is not None:
        st.line_chart(split_data[['Mechanical', 'Electrical']])
    else:
        st.write("Could not split data by type.")

    # 3. High Value Repair (XGBoost)
    st.subheader("3. High-Value Repair Probability (XGBoost)")
    imp, thresh = model_high_value_repair_xgb(df)
    if imp is not None:
        st.write(f"Key drivers for repairs costing {thresh}:")
        st.dataframe(imp, use_container_width=True)
    else:
        st.warning("XGBoost not available or insufficient data.")

    # 4. Spare Parts (NLP)
    st.subheader("4. Spare Part Classification (Zero-Shot Logic)")
    cats = model_spare_part_classifier(df)
    st.bar_chart(cats)

    # 5. Reliability (Survival)
    st.subheader("5. Top Failing Assets (Mean TBF)")
    tbf_data, msg = model_survival_analysis(df)
    if tbf_data is not None:
        st.dataframe(tbf_data.head(5), use_container_width=True)
    else:
        st.warning(msg)

    # 6. Markov Chain
    st.subheader("6. Operational State Transition (Markov)")
    trans_matrix = model_line_markov(df)
    st.write("Probability Matrix [Running, Down] -> [Running, Down]")
    st.write(trans_matrix)
    st.caption(f"Probability of staying Down if currently Down: {trans_matrix[1][1]:.1%}")

# --- COMPATIBILITY WRAPPERS ---
def forecast_spare_parts(df): return None, "Please use Deep Analyzer"
def forecast_cost_prophet(df): return model_total_cost_prophet(df)
def forecast_failure_rf(df): return None, "Included in Deep Analyzer"
